
# -------------------------
#       Training.py
#--------------------------

# The code is adapted from Classification_Task_-_Transfer_Learning.ipynb
# https://gitlab.com/netmode/sdg-text2kg/-/blob/main/Classification_Task_-_Transfer_Learning.ipynb?ref_type=heads
# and code generated by ChatGPT

from sentence_transformers import SentenceTransformer
from transformers import (
    BertForSequenceClassification,
    RobertaForSequenceClassification,
    XLNetForSequenceClassification, XLNetConfig,
    GPT2ForSequenceClassification, GPT2Config,
    GPTNeoForSequenceClassification, GPTNeoConfig,
    AutoModelForSequenceClassification, AutoTokenizer,
)
from transformers import AdamWeightDecay, get_linear_schedule_with_warmup
from data_prep import load_osdg_data, split_datasets
from tokenizer import tokenize_dataset
import torch
import datetime
import argparse

# === Hard-coded paths for each model and validation CSV ===
xlnet_path = "/Users/thidarat_mcair/Downloads/xlnet_model"
roberta_path = "/Users/thidarat_mcair/Downloads/roberta_model"
val_csv     = "/Users/thidarat_mcair/Downloads/cleaned_osdg_data.csv"

print(f"Loading model `{modelname}`...")

if modelname == "bert-base-uncased":
    model = BertForSequenceClassification.from_pretrained(
        modelname,
        num_labels=16,
        output_attentions=False,
        output_hidden_states=False,
    )

elif modelname == "roberta-base":
    model = RobertaForSequenceClassification.from_pretrained(
        modelname,
        num_labels=16,
        output_attentions=False,
        output_hidden_states=False,
    )

elif modelname == "xlnet-base-cased":
    model_config = XLNetConfig.from_pretrained(
        pretrained_model_name_or_path=modelname,
        num_labels=16,
        low_cpu_mem_usage=True,
        problem_type="multi_label_classification",
        output_attentions=False,
        output_hidden_states=False,
    )
    model = XLNetForSequenceClassification.from_pretrained(
        pretrained_model_name_or_path=modelname,
        config=model_config,
    )
    # Resize embeddings and fix padding token
    model.resize_token_embeddings(len(tokenizer))
    model.config.pad_token_id = model.config.eos_token_id

elif modelname == "gpt2":
    model_config = GPT2Config.from_pretrained(
        pretrained_model_name_or_path=modelname,
        num_labels=16,
        low_cpu_mem_usage=True,
        problem_type="multi_label_classification",
        output_attentions=False,
        output_hidden_states=False,
    )
    model = GPT2ForSequenceClassification.from_pretrained(
        pretrained_model_name_or_path=modelname,
        config=model_config,
    )
    model.resize_token_embeddings(len(tokenizer))
    model.config.pad_token_id = model.config.eos_token_id

elif "gpt-neo" in modelname:
    model_config = GPTNeoConfig.from_pretrained(
        pretrained_model_name_or_path=modelname,
        num_labels=16,
        low_cpu_mem_usage=True,
        problem_type="multi_label_classification",
        output_attentions=False,
        output_hidden_states=False,
    )
    model = GPTNeoForSequenceClassification.from_pretrained(
        pretrained_model_name_or_path=modelname,
        config=model_config,
    )
    model.resize_token_embeddings(len(tokenizer))
    model.config.pad_token_id = model.config.eos_token_id

elif "sentence-transformers" in modelname:
    print("Loading SBERT-based classification model...")
    model = AutoModelForSequenceClassification.from_pretrained(
        modelname,
        num_labels=16,
        problem_type="multi_label_classification",  # or "single_label_classification" if that’s your setup
        output_attentions=False,
        output_hidden_states=False,
        low_cpu_mem_usage=True,
    )
    # Resize embeddings in case your tokenizer has a different vocab size than the SBERT model’s original vocab
    model.resize_token_embeddings(len(tokenizer))
    # Some SBERT-based checkpoints may not have a pad_token_id set by default
    if getattr(model.config, "pad_token_id", None) is None:
        # Common workaround: use eos_token_id as pad
        model.config.pad_token_id = model.config.eos_token_id

else:
    raise ValueError(f"Unrecognized modelname: {modelname}")

# Move model to device
model.to(device)
print(f"Model loaded to `{device}`")
print_gpu_utilization()  # custom helper, optional

# 1) Inspect how many parameters there are
params = list(model.named_parameters())
print(f"The `{modelname}` model has {len(params)} named parameters.\n")

for name, p in params:
    print(f"{name:<55} {tuple(p.size())}")

# 2) Fine-tuning technique:
#  Freeze everything except the final encoder layer (12th layer in a 12-layer model, index 11)
#  and the classification head. For most Hugging Face models, the encoder layers are named differently by model types.

last_encoder_layer_num = 11  # zero-indexed; for a 12-layer model, layers are 0–11

frozen_param_patterns = []
trainable_param_patterns = []

for name, param in model.named_parameters():
    # Default: freeze everything
    param.requires_grad = False
    # Unfreeze if it belongs to the final encoder layer
    if modelname.startswith("bert-"):
        # BERT: "bert.encoder.layer.11..." is the final layer
        if f"bert.encoder.layer.{last_encoder_layer_num}." in name:
            param.requires_grad = True
            trainable_param_patterns.append(name)

    elif modelname.startswith("roberta-"):
        # RoBERTa: "roberta.encoder.layer.11..."
        if f"roberta.encoder.layer.{last_encoder_layer_num}." in name:
            param.requires_grad = True
            trainable_param_patterns.append(name)

    elif modelname == "xlnet-base-cased":
        # XLNet: "transformer.layer.11..."
        if f"transformer.layer.{last_encoder_layer_num}." in name:
            param.requires_grad = True
            trainable_param_patterns.append(name)

    elif modelname == "gpt2":
        # GPT-2: "transformer.h.11..."
        if f"transformer.h.{last_encoder_layer_num}." in name:
            param.requires_grad = True
            trainable_param_patterns.append(name)

    elif "gpt-neo" in modelname:
        # GPT-Neo: "transformer.h.11..."
        if f"transformer.h.{last_encoder_layer_num}." in name:
            param.requires_grad = True
            trainable_param_patterns.append(name)

    elif "sentence-transformers" in modelname:
        # We do a loose check for ".encoder.layer.11"
        if ".encoder.layer.11" in name:
            param.requires_grad = True
            trainable_param_patterns.append(name)

    # Always unfreeze the classification head itself:
    if "classifier" in name or "classification_head" in name or "pooler.dense" in name:
        param.requires_grad = True
        trainable_param_patterns.append(name)

# 3) Print out which parameters are trainable
print("\nOnly the following parameters will be trainable:")
print("===============================================")
for name, param in model.named_parameters():
    if param.requires_grad:
        print(name)

# Parameters Settings:
learning_rate = 5e-5
adam_epsilon = 1e-8
epochs = 3 # Number of training epochs (recommend between 2 and 4)

# Total number of training steps is [number of batches] x [number of epochs].
total_steps = len(train_dataloader) * epochs
print('Number of total training steps:',total_steps)

### Optimizer

# Transformers optimizer
optimizer =  AdamWeightDecay(model.parameters(),
                               lr = learning_rate, # default is 1e-3
                               eps = adam_epsilon, # default is 1e-8
                               weight_decay = 0.01,# default is 1e-2
                               correct_bias = False,
#                                no_deprecation_warning=True
                              )
# Torch optimizer
# optimizer =  torch.optim.AdamW(model.parameters(),
#                                lr = learning_rate, # default is 1e-3
#                                eps = adam_epsilon, # default is 1e-8
#                                weight_decay = 0.01,# default is 1e-2
#                               )

# Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0,
# after a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.

# warmup_steps: 10% of total steps
warmup_steps = round(total_steps*0.1)
scheduler = get_linear_schedule_with_warmup(optimizer,
                                            num_warmup_steps = warmup_steps, # Default value in run_glue.py
                                            num_training_steps = total_steps)

#--Utility : Format Elapsed time as hh:mm:ss
def format_time(elapsed):
    # Round to the nearest second.
    elapsed_rounded = int(round((elapsed)))
    # Format as hh:mm:ss
    return str(datetime.timedelta(seconds=elapsed_rounded))

#-------Training----------

# This training code is based on the `run_glue.py` script here:
# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128

# Set the seed value all over the place to make this reproducible.
seed_val = 46

random.seed(seed_val)
np.random.seed(seed_val)
torch.manual_seed(seed_val)
torch.cuda.manual_seed_all(seed_val)

# We'll store a number of quantities such as training and validation loss,
# validation accuracy, and timings.
training_stats = []

# Measure the total training time for the whole run.
total_t0 = time.time()

# For each epoch...
for epoch_i in range(0, epochs):

    # ========================================
    #               Training
    # ========================================

    # Perform one full pass over the training set.

    print("")
    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))
    print('Training...')

    # Measure how long the training epoch takes.
    t0 = time.time()

    # Reset the total loss for this epoch.
    total_train_loss = 0
    total_train_acc = 0
    total_train_f1 = 0

    # Put the model into training mode. Don't be mislead--the call to
    # `train` just changes the *mode*, it doesn't *perform* the training.
    # `dropout` and `batchnorm` layers behave differently during training
    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)

    model.train()

    # For each batch of training data...
    # Batch: List of 3 values [train_inputs, train_masks, train_labels]
    # Step: Len/Batch per Epoch
    for step, batch in enumerate(train_dataloader):
        # Progress update every 40 batches.
        if step % 40 == 0 and not step == 0:
            # Calculate elapsed time in minutes.
            elapsed = format_time(time.time() - t0)

            # Report progress.
            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))
            print_gpu_utilization()

        # Unpack this training batch from our dataloader.
        #
        # As we unpack the batch, we'll also copy each tensor to the GPU using the
        # `to` method.
        #
        # `batch` contains three pytorch tensors:
        #   [0]: input ids
        #   [1]: attention masks
        #   [2]: labels

        if torch.cuda.is_available():
            b_input_ids = batch[0].to(device)
            b_input_mask = batch[1].to(device)
            b_labels = batch[2].to(device)

        # Always clear any previously calculated gradients before performing a
        # backward pass. PyTorch doesn't do this automatically because
        # accumulating the gradients is "convenient while training RNNs".
        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)
        model.zero_grad()

        # Perform a forward pass (evaluate the model on this training batch).
        # The documentation for this `model` function is here:
        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification
        # It returns different numbers of parameters depending on what arguments
        # arge given and what flags are set. For our useage here, it returns
        # the loss (because we provided labels) and the "logits"--the model
        # outputs prior to activation.
        output = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)

        # One value
        loss = output.loss
        logits = output.logits

        # Actual labels
        if len(b_labels.size()) == 1:
            actual_targets = b_labels.to('cpu').numpy().flatten()

        else:
            actual_targets = torch.argmax(b_labels, dim=1).to('cpu').numpy().flatten()

        # Predicted labels
        logits = logits.detach().cpu().numpy()
        predicted_targets = np.argmax(logits, axis=1).flatten()

        # Accumulate the training loss over all of the batches so that we can
        # calculate the average loss at the end. `loss` is a Tensor containing a
        # single value; the `.item()` function just returns the Python value
        # from the tensor.
        total_train_loss += loss.item()
        total_train_acc += accuracy_score(actual_targets, predicted_targets)
        total_train_f1 += f1_score(actual_targets, predicted_targets, average='weighted', labels=list(np.arange(0, 16)),
                                   zero_division=0)

        # Perform a backward pass to calculate the gradients.
        loss.backward()

        # Clip the norm of the gradients to 1.0.
        # This is to help prevent the "exploding gradients" problem.
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        # Update parameters and take a step using the computed gradient.
        # The optimizer dictates the "update rule"--how the parameters are
        # modified based on their gradients, the learning rate, etc.
        optimizer.step()

        # Update the learning rate.
        scheduler.step()

    # Calculate the average loss over all of the batches for one epoch, that has 563-4 steps. Length of dataloader is the same with the number
    # of steps.
    avg_train_loss = total_train_loss / len(train_dataloader)
    avg_train_acc = total_train_acc / len(train_dataloader)
    avg_train_f1 = total_train_f1 / len(train_dataloader)

    # Measure how long this epoch took.
    training_time = format_time(time.time() - t0)

    print("")
    print("  Average training loss: {0:.2f}".format(avg_train_loss))
    print("  Average training accuracy: {0:.2f}".format(avg_train_acc))
    print("  Average training weighted F1 score: {0:.2f}".format(avg_train_f1))
    print("  Training epoch took: {:}".format(training_time))

    # ========================================
    #               Validation
    # ========================================
    # After the completion of each training epoch, measure our performance on
    # our validation set.

    print("")
    print("Running Validation...")

    t0 = time.time()

    # Put the model in evaluation mode--the dropout layers behave differently
    # during evaluation.
    model.eval()

    # Tracking variables
    total_eval_accuracy = 0
    total_eval_loss = 0
    total_eval_f1 = 0
    nb_eval_steps = 0

    actual_labels, predicted_labels = [], []

    # Evaluate data for one epoch
    for batch in validation_dataloader:

        # Unpack this training batch from our dataloader.
        #
        # As we unpack the batch, we'll also copy each tensor to the GPU using
        # the `to` method.
        #
        # `batch` contains three pytorch tensors:
        #   [0]: input ids
        #   [1]: attention masks
        #   [2]: labels

        if torch.cuda.is_available():
            b_input_ids = batch[0].to(device)
            b_input_mask = batch[1].to(device)
            b_labels = batch[2].to(device)

        # Tell pytorch not to bother with constructing the compute graph during
        # the forward pass, since this is only needed for backprop (training).
        with torch.no_grad():

            # Forward pass, calculate logit predictions.
            # token_type_ids is the same as the "segment ids", which
            # differentiates sentence 1 and 2 in 2-sentence tasks.
            # The documentation for this `model` function is here:
            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification
            # Get the "logits" output by the model. The "logits" are the output
            # values prior to applying an activation function like the softmax.
            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)

            loss = output.loss
            logits = output.logits

        # Move logits and labels to CPU
        logits = logits.detach().cpu().numpy()

        # Actual labels
        if len(b_labels.size()) == 1:
            label_ids = b_labels.to('cpu').numpy().flatten()
        else:
            label_ids = torch.argmax(b_labels, dim=1).to('cpu').numpy().flatten()

        # Extend actual_labels list with the new predicted labels of the batch
        actual_labels.extend(label_ids)

        # Extend predicted_labels list with the new predicted labels of the batch
        pred_flat = np.argmax(logits, axis=1).flatten()
        predicted_labels.extend(pred_flat)

        # Calculate the accuracy and f1 score for this batch of test sentences, and
        # accumulate it over all batches.
        total_eval_accuracy += accuracy_score(label_ids, pred_flat)
        total_eval_f1 += f1_score(label_ids, pred_flat, average='weighted', labels=list(np.arange(0, 16)),
                                  zero_division=0)

        # Accumulate the validation loss.
        total_eval_loss += loss.item()

    # Classification report
    print(classification_report(actual_labels, predicted_labels, labels=list(np.arange(0, 16)), zero_division=0))
    print_gpu_utilization()

    # Report the final accuracy for this validation run.
    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)
    print("  Accuracy: {0:.2f}".format(avg_val_accuracy))

    # Calculate the average loss over all of the batches.
    avg_val_loss = total_eval_loss / len(validation_dataloader)
    print("  Loss: {0:.2f}".format(avg_val_loss))

    # Calculate the average loss over all of the batches.
    avg_val_f1 = total_eval_f1 / len(validation_dataloader)

    # Measure how long the validation run took.
    validation_time = format_time(time.time() - t0)

    print("")
    print("  Average validation loss: {0:.2f}".format(avg_val_loss))
    print("  Average validation accuracy: {0:.2f}".format(avg_val_accuracy))
    print("  Average validation weighted F1 score: {0:.2f}".format(avg_val_f1))
    print("  Validation took: {:}".format(validation_time))

    # Record all statistics from this epoch.
    training_stats.append(
        {
            'epoch': epoch_i + 1,
            'Training Loss': avg_train_loss,
            'Training Accuracy': avg_train_acc,
            'Training F1 score': avg_train_f1,
            'Valid. Loss': avg_val_loss,
            'Valid. Accur.': avg_val_accuracy,
            'Valid. F1 score': avg_val_f1,
            'Training Time': training_time,
            'Validation Time': validation_time
        }
    )

print("")
print("Training complete!")

print("Total training took {:} (h:mm:ss)".format(format_time(time.time() - total_t0)))

    # Export the trained model to output_dir/final_model
    export_path = '/Users/thidarat_mcair/Downloads/final_model'
    trainer.save_model(export_path)
    print(f"Model exported to {export_path}")

if __name__ == '__main__':
    main()

    #/Users/thidarat_mcair/Downloads/cleaned_osdg_data.csv